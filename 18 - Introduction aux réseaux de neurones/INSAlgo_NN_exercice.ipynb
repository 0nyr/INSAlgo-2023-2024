{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercice : Perceptron simple\n",
        "\n",
        "Un perceptron est un modèle très simple (voir le plus simple) de reseaux de neurones. Il consiste simplement en une couche d'entrée (les inputs) et directement une couche de sortie (output) sans couches cachées entre les deux.\n",
        "\n",
        "![Illustration d'un peceptron](https://miro.medium.com/v2/resize:fit:256/format:webp/1*JLlHNhYjyY9h9y1D1sy8Zw.png)\n",
        "\n",
        "Nous allons entrainer notre modèle afin de classifier les images du dataset MNIST:\n",
        "\n",
        "![Illustration du dataset MNIST](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
        "\n",
        "Ce dataset est composé d'images de 28x28 representant des chiffres, le but va alors etre de classifier les images dans la bonne categorie.\n"
      ],
      "metadata": {
        "id": "IeF5GTrcwMpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports\n",
        "\n",
        "Afin de faciliter notre implementation, nous allons principalement utilisé la librairie Numpy, qui permet de gerer facilement des arrays en n dimensions.\n",
        "\n",
        "Pour de l'aide avec les operations sur les ndarray, appelez nous, [suivez ce tutoriel](https://numpy.org/doc/stable/user/quickstart.html), ou [cherchez dans la documentation](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)/google."
      ],
      "metadata": {
        "id": "z2ySkYXoyroW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops > /dev/null\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "z1R_U_thyv9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonctions pour load les données\n",
        "\n",
        "Ces fonctions mettent au bon format les données en entré"
      ],
      "metadata": {
        "id": "EVzyZGyKy3oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_src, train_tgt), (test_src, test_tgt) = mnist.load_data()\n",
        "train_src = rearrange(train_src,'i w h -> i (w h)')/255\n",
        "test_src = rearrange(test_src,'i w h -> i (w h)')/255"
      ],
      "metadata": {
        "id": "mNiQzsrcz9Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_one_hot = np.zeros((len(train_tgt), 10))\n",
        "train_labels_one_hot[range(len(train_tgt)), train_tgt] = 1\n",
        "train_tgt = train_labels_one_hot"
      ],
      "metadata": {
        "id": "t3Km4ilb6Jvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels_one_hot = np.zeros((len(test_tgt), 10))\n",
        "test_labels_one_hot[range(len(test_tgt)), test_tgt] = 1\n",
        "test_tgt = test_labels_one_hot"
      ],
      "metadata": {
        "id": "aJm11zOT6JoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_by_batches(dataset, batch_size):\n",
        "    for i in range(math.ceil(dataset.shape[0] / batch_size)):\n",
        "        yield dataset[i * batch_size:i * batch_size + batch_size]"
      ],
      "metadata": {
        "id": "WdL1VnuN9YaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model et code à completer\n",
        "\n",
        "Voici le code a completer, ce code est separé en 3 étapes:\n",
        "\n",
        "\n",
        "*   L'initialisation du model\n",
        "*   La passe avant\n",
        "*   La passe arrière\n",
        "\n",
        "Pour les passes, toutes les formules sont dans les slides a différents endroits, à vous de retrouver les bonnes forumules et les mettre au bon endroit.\n",
        "\n",
        "Vous avez peut etre remarqué l'utilisation d'une variable batch_size, si cela vous pose des problème, ou que vous voulez plus d'informations, demendez, c'est une partie qui a volontairment été laissée de coté afin de pratiquer plus rapidement.\n",
        "\n"
      ],
      "metadata": {
        "id": "MqQF2srv9r2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "        # TODO #1 : Initialiser le model\n",
        "        self.weight = None\n",
        "        self.bias = None\n",
        "\n",
        "        self.learning_rate = None\n",
        "        self.batch_size = 16\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO #2 : implementer la passe vers l'avant\n",
        "        pass\n",
        "\n",
        "    def backpropagate(self,x,output,tgt):\n",
        "        # TODO #3 : implementer la passe vers l'arriere\n",
        "        pass"
      ],
      "metadata": {
        "id": "VmjSbi3v9rbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, vous retrouvez les quelques fonction mentionnées dans les slides, certaines peuvent vous etres utiles dans l'exercice"
      ],
      "metadata": {
        "id": "n6ZyYrN_11MU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction utiles\n",
        "\n",
        "def softmax( x):\n",
        "    x = np.exp(x)\n",
        "    return x / x.sum(axis=1, keepdims=True)\n",
        "\n",
        "def compute_accuracy(output, tgt):\n",
        "    acc = tgt.argmax(axis=1) - output.argmax(axis=1)\n",
        "    acc = acc.shape[0] - np.count_nonzero(acc)\n",
        "    return acc\n",
        "\n",
        "def compute_loss(output, tgt):\n",
        "    return -np.log(np.max(output * tgt, axis=1)).sum()"
      ],
      "metadata": {
        "id": "1v_1M7lw-DS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training du model"
      ],
      "metadata": {
        "id": "3kP_udwi-M73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, src, tgt, src_test, tgt_test):\n",
        "    epoch = 1\n",
        "\n",
        "    acc = []\n",
        "    loss = []\n",
        "\n",
        "    acc_test = []\n",
        "    loss_test = []\n",
        "    while True:\n",
        "        print(f\"Epoch #{epoch}\")\n",
        "\n",
        "        acc.append(0)\n",
        "        loss.append(0)\n",
        "\n",
        "        for x, y in zip(load_by_batches(src, model.batch_size), load_by_batches(tgt, model.batch_size)):\n",
        "\n",
        "            output = model.forward(x)\n",
        "            assert output.shape == y.shape\n",
        "            acc[-1] += compute_accuracy(output, y)\n",
        "            l = compute_loss(output, y)\n",
        "            loss[-1] += l\n",
        "\n",
        "            model.backpropagate(x, output, y)\n",
        "        acc[-1] /= src.shape[0]\n",
        "        loss[-1] /= src.shape[0]\n",
        "\n",
        "        output = model.forward(src_test)\n",
        "        acc_test.append(compute_accuracy(output, tgt_test))\n",
        "        l = compute_loss(output, tgt_test)\n",
        "        loss_test.append(l)\n",
        "        acc_test[-1] /= src_test.shape[0]\n",
        "        loss_test[-1] /= src_test.shape[0]\n",
        "\n",
        "        print(f'Train| Accuracy: {acc[-1]:.3} - Loss: {loss[-1]:.3}')\n",
        "        print(f'Test| Accuracy: {acc_test[-1]:.3} - Loss: {loss_test[-1]:.3}')\n",
        "        print()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            fig, axs = plt.subplots(2, 2)\n",
        "\n",
        "            axs[0, 0].plot(acc)\n",
        "            axs[1, 0].plot(loss)\n",
        "            axs[0, 1].plot(acc_test, 'tab:orange')\n",
        "            axs[1, 1].plot(loss_test, 'tab:orange')\n",
        "\n",
        "            axs[0, 0].grid(True)\n",
        "            axs[1, 0].grid(True)\n",
        "            axs[0, 1].grid(True)\n",
        "            axs[1, 1].grid(True)\n",
        "\n",
        "            axs[0, 0].set_title('Train dataset')\n",
        "            axs[0, 1].set_title('Test dataset')\n",
        "            axs[0, 0].set(ylabel='Accuracy')\n",
        "            axs[1, 0].set(ylabel='Loss')\n",
        "\n",
        "            plt.show()\n",
        "        epoch += 1"
      ],
      "metadata": {
        "id": "lBAVgQeF-MgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(train_src.shape[1], train_tgt.shape[1])\n",
        "train_model(model, train_src, train_tgt, test_src, test_tgt)"
      ],
      "metadata": {
        "id": "Y-Q7WkAH-UDV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}